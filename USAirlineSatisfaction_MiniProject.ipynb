{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aea72987",
   "metadata": {},
   "source": [
    "# US Airline Satisfaction Mini Project \n",
    "\n",
    "In this Project, we would like to peform some analysis on a dataset of __[US Airline passenger satisfaction survey](https://www.kaggle.com/datasets/najibmh/us-airline-passenger-satisfaction-survey?resource=download)__.\n",
    "\n",
    "## Contents\n",
    "- [Problem](#problem)\n",
    "- [Data Preparation](#data-preparation)\n",
    "- [Exploratory Analysis](#exploratory-analysis)\n",
    "- [Models](#models)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6465bbf",
   "metadata": {},
   "source": [
    "<a id=\"problem\"></a>\n",
    "## Problem\n",
    "Based on passenger ratings, we would like to find out how the different indivudal ratings affect the passenger's final decision for a _satisfied_ or _unsatisfied_ with the service provided by US Airline.\n",
    "\n",
    "**Specifically**:\n",
    "1. Can we predict if customer would be satified?\n",
    "1. What are the most important factors that affect customer satisfaction?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd6a7e3",
   "metadata": {},
   "source": [
    "<a id=\"data-preparation\"></a>\n",
    "## Data Preparation\n",
    "\n",
    "### Essential Libraries\n",
    "\n",
    "Let us begin by importing the essential Python Libraries.\n",
    "\n",
    "> NumPy : Library for Numeric Computations in Python  \n",
    "> Pandas : Library for Data Acquisition and Preparation  \n",
    "> Matplotlib : Low-level library for Data Visualization  \n",
    "> Seaborn : Higher-level library for Data Visualization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04a68fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "sb.set() # set the default Seaborn style for graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08701de",
   "metadata": {},
   "source": [
    "### Import the Dataset\n",
    "Source: __[US Airline passenger satisfaction survey](https://www.kaggle.com/datasets/najibmh/us-airline-passenger-satisfaction-survey?resource=download)__\n",
    "\n",
    "Attached file: `satisfaction_v2.csv`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ddc3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "satisfactionData = pd.read_csv('satisfaction.csv')\n",
    "satisfactionData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec20906",
   "metadata": {},
   "outputs": [],
   "source": [
    "satisfactionData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c663c464",
   "metadata": {},
   "source": [
    "#### Initial Observations\n",
    "* There are `24` columns and `129880` rows in the dataset.   \n",
    "* The response variable seems to be `satisfaction_v2`.\n",
    "* The following `5` columns are non-predictor/unlikly to be predictors: ID, Gender, Customer Type, Age and Type of Travel.\n",
    "* The remaining `18` columns are potential predictor variables.\n",
    "\n",
    "#### Predictor Variables\n",
    "* There are `16` variables identified as `int64` by default. But it seems like only `Flight Distance` and `Departure Delay in Minutes` are actually numeric. The remaining `14` variables are ratings from 0 to 5 and should be considered as Categorical.\n",
    "* The `Arrivial Delay in Minutes` variable identified as `float64` by default, and it seems to be Numeric.\n",
    "* The`Class` variable identified as `object` by default, and are most likely Categorical.  \n",
    "* We noted that `Arrivial Delay in Minutes` seems to be missing some values.\n",
    "\n",
    "### Dataset Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c38e00",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Missing Values: </b> It's noted that <code>Arrivial Delay in Minutes</code> has count <code>129487</code> instead of <code>129880</code>. This is due to it containing <code>NULL</code> values. We will replace them with <code>0</code> here.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfd2d29",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check count\n",
    "satisfactionData['Arrival Delay in Minutes'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b57042",
   "metadata": {},
   "outputs": [],
   "source": [
    "satisfactionData['Arrival Delay in Minutes'].fillna(value=0, inplace=True)\n",
    "# Check count\n",
    "satisfactionData['Arrival Delay in Minutes'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd689d03",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    Check that the <code>id</code>s are unique. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef2c82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(satisfactionData[\"id\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784285c2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ordinal Categorical Variables</b><br>\n",
    "    Most ordinal categorical variables are rating types in the <code>int</code> form. No conversion required. <br>\n",
    "    But we will convert for <code>non-int</code> types <code>Class</code> and <code>Customer Type</code> in \n",
    "    <a href=\"#exploratory-analysis\">Exploratory Analysis</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9d61a6",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"exploratory-analysis\"></a>\n",
    "## Exploratory Analysis\n",
    "\n",
    "### Response Variable\n",
    "Lets take a look at the response variable `satisfaction_v2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b96f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.catplot(y = 'satisfaction_v2', data = satisfactionData, kind = \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ff85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "countG, countB = satisfactionData['satisfaction_v2'].value_counts()\n",
    "print(\"[satisfied] : [neutral/dissatisfied] = [\", countG, \"] : [\", countB, \"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdf14d3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    The <code>satisfied</code> to <code>neutral/dissatisfied</code> ratio of <code> 71087 : 58794 </code> is acceptable. We will not perform any rebalancing. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b14752e",
   "metadata": {},
   "source": [
    "### Predictor Variables\n",
    "Lets take a look at the `18` predictor variables.<br>\n",
    "We shall split them into the following subcategories.\n",
    "\n",
    "* Passenger: variables relating to the passenger.\n",
    "* Service: variables corresponding to the services provided by the airline.\n",
    "* Others: variables that are do not fall in the above categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd08f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "satisfactionData.iloc[:,6:24].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60fe325",
   "metadata": {},
   "source": [
    "<a id=\"passenger-variables-ea\"></a>\n",
    "#### Passenger Variables\n",
    "Variables relating to the passenger. <br>\n",
    "**Categorical** : \n",
    "[`Class`](#class-ea)\n",
    "[`Type of Travel`](#type-of-travel-ea)\n",
    "[`Customer Type`](#customer-type-ea)\n",
    "[`Gender`](#gender-ea) <br>\n",
    "\n",
    "**Numeric** : [`Age`](#age-ea) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4750c817",
   "metadata": {},
   "source": [
    "<a id=\"class-ea\"></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Class (Categorical)</b><br>\n",
    "    The class variable seems to describle the type of flight class the passenger was in.<br>\n",
    "    Since this is normally choosen by the passenger, we labeled it under <b>Passenger Variables</b><br>\n",
    "    <b>Values</b><br>\n",
    "    We observed that there are 3 unique values for <code>Class</code> variable.<br>\n",
    "    It seems like their ordinal values(ascending) are as follows:<br>\n",
    "    1: <code>Eco</code> 2: <code>Eco Plus</code> 3: <code>Business</code><br> \n",
    "    We will convert them accordingly. <br>\n",
    "    <b>Distribution</b><br>\n",
    "    The most common value is <code>Business</code> which is followed closely by <code>Eco</code>.<br>    \n",
    "    <code>Eco Plus</code> has the least distribution. <br>\n",
    "    <b>Relation</b><br>\n",
    "    <code>Business</code> class have the higest satisfied rate while passengers from <code>Eco</code> and\n",
    "    <code>Eco Plus</code> have higher neutral/disatisfied ratings.\n",
    "    <br><br><a href=\"#passenger-variables-ea\">Return</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1597f310",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(satisfactionData['Class'].describe())\n",
    "classTypes = satisfactionData['Class'].unique()\n",
    "print(classTypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892f729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "cat_type_class = CategoricalDtype(categories=['Eco', 'Eco Plus', 'Business'], ordered=True)\n",
    "satisfactionData['Class'] = satisfactionData[\"Class\"].astype(cat_type_class)\n",
    "satisfactionData['Class'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525b6bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.catplot(x = 'Class', data = satisfactionData, kind = \"count\", aspect= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cf2f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.catplot(x='Class', data = satisfactionData, hue= 'satisfaction_v2', kind = \"count\", aspect= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8c445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# satisfaction_v2 vs Class\n",
    "f = plt.figure(figsize=(15, 4))\n",
    "sb.heatmap(satisfactionData.groupby(['satisfaction_v2', 'Class']).size().unstack(), \n",
    "           linewidths = 1, annot = True, fmt = 'g', annot_kws = {\"size\": 18}, cmap = \"BuGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7061245",
   "metadata": {},
   "source": [
    "<a id=\"type-of-travel-ea\"></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Type of Travel (Categorical)</b><br>\n",
    "    This variable seems to describle type/purpose of travel of the passenger.<br>\n",
    "    <b>Values</b><br>\n",
    "    We observed that there are 2 unique values <code>Personal Travel</code> <code>Business travel</code> <br>\n",
    "    <b>Distribution</b><br>\n",
    "    <code>Business travel</code> has the higher distribution of 89693. <br>\n",
    "    <b>Relation</b><br>\n",
    "    <code>Business travel</code> appears to have higher satisfaction\n",
    "    <br><br><a href=\"#passenger-variables-ea\">Return</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af49db1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(satisfactionData['Type of Travel'].describe())\n",
    "travelTypes = satisfactionData['Type of Travel'].unique()\n",
    "print(travelTypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bf9e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.catplot(x = 'Type of Travel', data = satisfactionData, kind = \"count\", \n",
    "           aspect= 2, order=['Business travel', 'Personal Travel'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdbaff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.catplot(x = 'Type of Travel', data = satisfactionData, kind = \"count\", hue=\"satisfaction_v2\",\n",
    "           aspect= 2, order=['Business travel', 'Personal Travel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c616dec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# satisfaction_v2 vs Customer Type\n",
    "f = plt.figure(figsize=(15, 4))\n",
    "sb.heatmap(satisfactionData.groupby(['satisfaction_v2', 'Type of Travel']).size().unstack(), \n",
    "           linewidths = 1, annot = True, fmt = 'g', annot_kws = {\"size\": 18}, cmap = \"BuGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffb126f",
   "metadata": {},
   "source": [
    "<a id=\"customer-type-ea\"></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Customer Type (Categorical)</b><br>\n",
    "    This variable seems to describle if passenger is a loyal customer.<br>\n",
    "    <b>Values</b><br>\n",
    "    We observed that there are 2 unique values <code>Loyal Customer</code> <code>disloyal Customer</code> <br>\n",
    "    We will assign them the weights as follows: <br>\n",
    "    1: <code>disloyal Customer</code> 2: <code>Loyal Customer</code> <br>\n",
    "    <b>Distribution</b><br>\n",
    "    <code>Loyal Customer</code> has the higher distribution of 106100. <br>\n",
    "    <b>Relation</b><br>\n",
    "    <code>Loyal Customer</code> appears to have higher satisfaction rate\n",
    "    <br><br><a href=\"#passenger-variables-ea\">Return</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed3ae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "satisfactionData = pd.read_csv('satisfaction.csv')\n",
    "print(satisfactionData['Customer Type'].describe())\n",
    "customerTypes = satisfactionData['Customer Type'].unique()\n",
    "print(customerTypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8153cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_type_customer = CategoricalDtype(categories=['disloyal Customer', 'Loyal Customer'], ordered=True)\n",
    "satisfactionData['Customer Type'] = satisfactionData['Customer Type'].astype(cat_type_customer)\n",
    "satisfactionData['Customer Type'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e537339f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.catplot(x = 'Customer Type', data = satisfactionData, kind = \"count\", aspect= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a931145",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.catplot(x = 'Customer Type', data = satisfactionData, \n",
    "           hue=\"satisfaction_v2\", kind = \"count\", aspect= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4777fe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# satisfaction_v2 vs Customer Type\n",
    "f = plt.figure(figsize=(15, 4))\n",
    "sb.heatmap(satisfactionData.groupby(['satisfaction_v2', 'Customer Type']).size().unstack(), \n",
    "           linewidths = 1, annot = True, fmt = 'g', annot_kws = {\"size\": 18}, cmap = \"BuGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef015ea",
   "metadata": {},
   "source": [
    "<a id=\"gender-ea\"></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Gender (Categorical)</b><br>\n",
    "    <b>Values</b><br>\n",
    "    There are 2 unique values <code>Male</code> and <code>Female</code> <br>\n",
    "    <b>Distribution</b><br>\n",
    "    Even distribution 63981 : 65899  <br>\n",
    "    <b>Relation</b><br>\n",
    "    It appears that <code>Female</code> passengers have a higher satisfaction rate   \n",
    "    <br><br><a href=\"#passenger-variables-ea\">Return</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dcc2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "satisfactionData['Gender'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375423e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.catplot(x = 'Gender', data = satisfactionData, kind = \"count\", aspect= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82b79f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.catplot(x = 'Gender', data = satisfactionData, \n",
    "           hue=\"satisfaction_v2\", kind = \"count\", aspect= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c164ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# satisfaction_v2 vs Gender\n",
    "f = plt.figure(figsize=(15, 4))\n",
    "sb.heatmap(satisfactionData.groupby(['satisfaction_v2', 'Gender']).size().unstack(), \n",
    "           linewidths = 1, annot = True, fmt = 'g', annot_kws = {\"size\": 18}, cmap = \"BuGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff3aa53",
   "metadata": {},
   "source": [
    "<a id=\"age-ea\"></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Age (Numeric)</b><br>\n",
    "    <b>Values</b><br>\n",
    "    There are 2 unique values <code>Male</code> and <code>Female</code> <br>\n",
    "    <b>Relation</b><br>\n",
    "    It appears that ages <code>40</code> to <code>60</code>passengers have a higher satisfaction rate    \n",
    "    <br><br><a href=\"#passenger-variables-ea\">Return</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82df81b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "satisfactionData['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50ac810",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(3, 1, figsize=(64, 32))\n",
    "sb.boxplot(data = satisfactionData['Age'], orient = \"h\", ax = axes[0])\n",
    "sb.histplot(data = satisfactionData['Age'], ax = axes[1])\n",
    "sb.violinplot(data = satisfactionData['Age'], orient = \"h\", ax = axes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812693a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(3, 1, figsize=(64, 64))\n",
    "sb.boxplot(data = satisfactionData, orient = \"h\", ax = axes[0],\n",
    "          x ='Age', y = 'satisfaction_v2')\n",
    "sb.kdeplot(data = satisfactionData, ax = axes[1],\n",
    "          x ='Age', hue = 'satisfaction_v2')\n",
    "sb.violinplot(data = satisfactionData, orient = \"h\", ax = axes[2],\n",
    "          x ='Age', y = 'satisfaction_v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9437ab",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Age + Gender</b><br>\n",
    "    Analyse the relation with Age + Gender.<br>\n",
    "    We observe that the graphs are fairly similar. Not much difference in relation.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df6c273",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.catplot(x = 'Age', y = 'satisfaction_v2', row = 'Gender', data = satisfactionData, kind = 'box', aspect = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c1ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.catplot(x = 'Age', y = 'satisfaction_v2', row = 'Gender', \n",
    "           data = satisfactionData, kind = 'violin', aspect = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252da6cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6440e4a",
   "metadata": {},
   "source": [
    "<a id=\"service-variables-ea\"></a>\n",
    "#### Service Variables\n",
    "For our problem case, we will be focusing mainly on services on board the plane.<br>\n",
    "**Focus**:\n",
    "<code>Seat comfort</code> \n",
    "<code>Food and drink</code> \n",
    "<code>Inflight wifi service</code> \n",
    "<code>Inflight entertainment</code> \n",
    "<code>On-board service</code> \n",
    "<code>Leg room service</code> \n",
    "<code>Checkin service</code>\n",
    "<code>Cleanliness</code>\n",
    "\n",
    "**Non-Focus**:\n",
    "<code>Online support</code> \n",
    "<code>Ease of Online booking</code> \n",
    "<code>Baggage handling</code>\n",
    "<code>Online boarding</code>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490af6b3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Focus Service Variables (Categorical)</b><br>\n",
    "    <b>Values</b><br>\n",
    "    We observed that there are 6 unique values from 0 to 6.<br>\n",
    "    All of which are <i>rating</i> type variables.<br>\n",
    "    <b>Relation</b><br>\n",
    "    We observed that generally, ratings 5 and 6 have higher statisfaction rate.<br>\n",
    "    But more notably, \n",
    "    <code>Seat comfort</code>\n",
    "    <code>Food and drink</code>\n",
    "    <code>Inflight entertainment</code> seems to have strong relation to satisfaction. <br>\n",
    "    Specifically speaking, ratings 5 and 6 have higher statisfaction rate and additionally,<br>\n",
    "    ratings 3 and 4 have higher neutral/distatisfaction rate\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb8e907",
   "metadata": {},
   "outputs": [],
   "source": [
    "focusVariables = ['Seat comfort', 'Food and drink', \n",
    "                  'Inflight wifi service', 'Inflight entertainment',\n",
    "                  'On-board service','Leg room service','Checkin service',\n",
    "                  'Cleanliness']\n",
    "\n",
    "satisfactionData[focusVariables].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71e22d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import asyncio\n",
    "\n",
    "def printHeader(col, phref):\n",
    "    markdown = f'<div class=\"alert alert-block alert-info\"><b>{col}</b><br><br><a href=\"#{phref}\">Return</a></div>'\n",
    "    display(Markdown(markdown))\n",
    "\n",
    "def printExploratoryAnalysis(col, data, dataType, parentSectionId):\n",
    "    printHeader(col, parentSectionId)\n",
    "    if(dataType=='categorical'):\n",
    "        sb.catplot(x = col, data = data, kind = \"count\", aspect= 2)\n",
    "        sb.catplot(x = col, data = data, hue=\"satisfaction_v2\", kind = \"count\", aspect= 2)\n",
    "        f = plt.figure(figsize=(15, 4))\n",
    "        sb.heatmap(satisfactionData.groupby(['satisfaction_v2', col]).size().unstack(),\n",
    "                         linewidths = 1, annot = True, fmt = 'g', annot_kws = {\"size\": 18}, cmap = \"BuGn\")\n",
    "        plt.show()\n",
    "    elif(dataType=='Numerical'):\n",
    "        f, axes = plt.subplots(3, 1, figsize=(64, 32))\n",
    "        bp = sb.boxplot(data = satisfactionData[col], orient = \"h\", ax = axes[0])\n",
    "        hp = sb.histplot(data = satisfactionData[col], ax = axes[1])\n",
    "        vp = sb.violinplot(data = satisfactionData[col], orient = \"h\", ax = axes[2])\n",
    "        f, axes = plt.subplots(3, 1, figsize=(64, 48))\n",
    "        rbp = sb.boxplot(data = departDelayDataClean, orient = \"h\",\n",
    "                   x = col, y = 'satisfaction_v2', ax = axes[0])\n",
    "        rkp = sb.kdeplot(data = departDelayDataClean,\n",
    "                   x= col, hue='satisfaction_v2', ax = axes[1])\n",
    "        rvp = sb.violinplot(data = departDelayDataClean, orient = \"h\",\n",
    "               x = col, y = 'satisfaction_v2', ax = axes[2])\n",
    "        plt.show()\n",
    "    display(Markdown('---'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305575d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for var in focusVariables:\n",
    "    printExploratoryAnalysis(var, satisfactionData, 'categorical', 'service-variables-ea')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4977b0bf",
   "metadata": {},
   "source": [
    "<a id=\"other-variables-ea\"></a>\n",
    "#### Other Variables\n",
    "Other variables that are not related to customer or airline service. <br>\n",
    "<b>Categorical</b>: \n",
    "<a href=\"#gate-location-ea\"><code>Gate location</code></a>\n",
    "<a href=\"#departure-arrival-convenient-ea\"><code>Departure/Arrival convenient</code></a>\n",
    "<br>\n",
    "<b>Numeric</b> : \n",
    "<a href=\"#flight-distance-ea\"><code>Flight Distance</code></a>\n",
    "<a href=\"#departure-delay-ea\"><code>Departure Delay in Minutes</code></a>\n",
    "<a href=\"#arrival-delay-ea\"><code>Arrival Delay in Minutes</code></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c90e28",
   "metadata": {},
   "source": [
    "<a id=\"gate-location-ea\"></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Gate Location (Categorical)</b><br>\n",
    "    This variable most likely represent the convenience of the gate location.<br>\n",
    "    As the airline may not choose their gate location, we did not include under service.<br>\n",
    "    <b>Values</b><br>\n",
    "    We observed that there are 6 unique values from 0 to 6.<br>\n",
    "    It is a <i>rating</i> type variable.<br>\n",
    "    <b>Distribution</b><br>\n",
    "    Rating <code>3</code> has the highest distribution. <br>\n",
    "    Rating <code>0</code> has the lowest distribution. <br>\n",
    "    <b>Relation</b><br>\n",
    "    <code>Loyal Customer</code> appears to have higher satisfaction rate \n",
    "    <br><br><a href=\"#other-variables-ea\">Return</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a4c324",
   "metadata": {},
   "outputs": [],
   "source": [
    "satisfactionData['Gate location'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5740c51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(15,8))\n",
    "sb.catplot(x = 'Gate location', data = satisfactionData, kind = \"count\", aspect= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf900c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.catplot(x = 'Gate location', data = satisfactionData, \n",
    "           hue=\"satisfaction_v2\", kind = \"count\", aspect= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc292396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# satisfaction_v2 vs Gate location\n",
    "f = plt.figure(figsize=(15, 4))\n",
    "sb.heatmap(satisfactionData.groupby(['satisfaction_v2', 'Gate location']).size().unstack(), \n",
    "           linewidths = 1, annot = True, fmt = 'g', annot_kws = {\"size\": 18}, cmap = \"BuGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf9cf50",
   "metadata": {},
   "source": [
    "<a id=\"departure-arrival-convenient-ea\"></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Departure/Arrival time convenient (Categorical)</b><br>\n",
    "    This variable seems to describle covenience of the flight departure and arrival times.<br>\n",
    "    Although flight timings are provided by the airline, the passenger normally pick the timeslot.<br>\n",
    "    As such, we labeled it under <b>Other Variables</b><br>\n",
    "    <b>Values</b><br>\n",
    "    We observed that there are 6 unique values from 0 to 6.<br>\n",
    "    It is a <i>rating</i> type variable.<br>\n",
    "    <b>Distribution</b><br>\n",
    "    Rating <code>3</code> has the highest distribution followed closely by <code>2</code> and <code>4</code><br>    \n",
    "    Rating <code>0</code> has the lowest distribution. <br>\n",
    "    <b>Relation</b>\n",
    "    <br><br><a href=\"#other-variables-ea\">Return</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0b4d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "satisfactionData[['Departure/Arrival time convenient']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960466c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.catplot(x = 'Departure/Arrival time convenient', data = satisfactionData, kind = \"count\", aspect= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f874461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.catplot(x = 'Departure/Arrival time convenient', data = satisfactionData, \n",
    "           hue=\"satisfaction_v2\", kind = \"count\", aspect= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9e4832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# satisfaction_v2 vs Departure/Arrival time convenient\n",
    "f = plt.figure(figsize=(15, 4))\n",
    "sb.heatmap(satisfactionData.groupby(['satisfaction_v2', 'Departure/Arrival time convenient']).size().unstack(), \n",
    "           linewidths = 1, annot = True, fmt = 'g', annot_kws = {\"size\": 18}, cmap = \"BuGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52ce373",
   "metadata": {},
   "source": [
    "<a id=\"flight-distance-ea\"></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Flight Distance (Numeric)</b><br>\n",
    "    This variable describes the flight distance most likely in miles.<br>\n",
    "    <b>Relation</b><br>\n",
    "    It appears that at below <code>1000</code> miles, satisfaction rate seems to be higher.\n",
    "    <br><br><a href=\"#other-variables-ea\">Return</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60db7de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "satisfactionData['Flight Distance'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c4628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(3, 1, figsize=(64, 32))\n",
    "sb.boxplot(data = satisfactionData['Flight Distance'], orient = \"h\", ax = axes[0])\n",
    "sb.histplot(data = satisfactionData['Flight Distance'], ax = axes[1])\n",
    "sb.violinplot(data = satisfactionData['Flight Distance'], orient = \"h\", ax = axes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5106e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(15, 8))\n",
    "sb.boxplot(data = satisfactionData, orient = \"h\",\n",
    "          x ='Flight Distance', y = 'satisfaction_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bfa637",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(15, 8))\n",
    "sb.kdeplot(data = satisfactionData, x='Flight Distance',hue='satisfaction_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d603237",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(15,8))\n",
    "sb.violinplot(data = satisfactionData, orient = 'h',\n",
    "              x = 'Flight Distance', y = 'satisfaction_v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4ea17c",
   "metadata": {},
   "source": [
    "<a id=\"departure-delay-ea\"></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Departure Delay in Minutes (Numeric)</b><br>\n",
    "    We excluded <code>0</code> departure delays<br>\n",
    "    <br><br><a href=\"#other-variables-ea\">Return</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06ff239",
   "metadata": {},
   "outputs": [],
   "source": [
    "satisfactionData['Departure Delay in Minutes'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe466e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "departDelayData = satisfactionData.loc[~((satisfactionData['Departure Delay in Minutes'] == 0))]\n",
    "departDelayData['Departure Delay in Minutes'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3ab8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(3, 1, figsize=(64, 32))\n",
    "sb.boxplot(data = departDelayData[['Departure Delay in Minutes']], orient = \"h\", ax = axes[0])\n",
    "sb.histplot(data = departDelayData[['Departure Delay in Minutes']], ax = axes[1])\n",
    "sb.violinplot(data = departDelayData[['Departure Delay in Minutes']], orient = \"h\", ax = axes[2])\n",
    "#sb.boxplot(data = departDelayData[['Departure Delay in Minutes']], orient = \"h\",showfliers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db90417d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Remove outliers</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afc160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "departDelayDataClean = departDelayData[['Departure Delay in Minutes','satisfaction_v2']].copy()\n",
    "# Calculate the quartiles\n",
    "Q1 = departDelayDataClean.quantile(0.25)\n",
    "Q3 = departDelayDataClean.quantile(0.75)\n",
    "# Rule to identify outliers\n",
    "rule = ((departDelayDataClean < (Q1 - 1.5 * (Q3 - Q1))) \n",
    "        | (departDelayDataClean > (Q3 + 1.5 * (Q3 - Q1))))\n",
    "departDelayOutliers = rule.any(axis = 1)\n",
    "departDelayOutlierindices = departDelayOutliers.index[departDelayOutliers == True]\n",
    "\n",
    "# Remove the outliers based on the row indices obtained above\n",
    "departDelayDataClean.drop(axis = 0,               # 0 drops row 1 drops column\n",
    "                          index = departDelayOutlierindices, # this takes a list as input\n",
    "                          inplace = True)         # not overwritten by default \n",
    "# Check the clean data\n",
    "departDelayDataClean['Departure Delay in Minutes'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975bed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(3, 1, figsize=(64, 32))\n",
    "sb.boxplot(data = departDelayDataClean[['Departure Delay in Minutes']], orient = \"h\", ax = axes[0])\n",
    "sb.histplot(data = departDelayDataClean[['Departure Delay in Minutes']], ax = axes[1])\n",
    "sb.violinplot(data = departDelayDataClean[['Departure Delay in Minutes']], orient = \"h\", ax = axes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae433cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(3, 1, figsize=(64, 48))\n",
    "sb.boxplot(data = departDelayDataClean, orient = \"h\",\n",
    "           x ='Departure Delay in Minutes', y = 'satisfaction_v2', ax = axes[0])\n",
    "sb.kdeplot(data = departDelayDataClean, \n",
    "           x='Departure Delay in Minutes', hue='satisfaction_v2', ax = axes[1])\n",
    "sb.violinplot(data = departDelayDataClean, orient = \"h\",\n",
    "               x ='Departure Delay in Minutes', y = 'satisfaction_v2', ax = axes[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9779a59",
   "metadata": {},
   "source": [
    "<a id=\"arrival-delay-ea\"></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Arrival Delay in Minutes (Numeric)</b><br>\n",
    "    We excluded <code>0</code> departure delays<br>\n",
    "    <br><br><a href=\"#other-variables-ea\">Return</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f78f7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "arriveDelayData = satisfactionData.loc[~((satisfactionData['Arrival Delay in Minutes'] == 0))]\n",
    "arriveDelayData['Arrival Delay in Minutes'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351882f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "arriveDelayDataClean = arriveDelayData[['Arrival Delay in Minutes','satisfaction_v2']].copy()\n",
    "# Calculate the quartiles\n",
    "adQ1 = arriveDelayDataClean.quantile(0.25)\n",
    "adQ3 = arriveDelayDataClean.quantile(0.75)\n",
    "# Rule to identify outliers\n",
    "adrule = ((arriveDelayDataClean < (adQ1 - 1.5 * (adQ3 - adQ1))) \n",
    "        | (arriveDelayDataClean > (adQ3 + 1.5 * (adQ3 - adQ1))))\n",
    "arriveDelayOutliers = adrule.any(axis = 1)\n",
    "arriveDelayOutlierindices = arriveDelayOutliers.index[arriveDelayOutliers == True]\n",
    "\n",
    "# Remove the outliers based on the row indices obtained above\n",
    "arriveDelayDataClean.drop(axis = 0,               # 0 drops row 1 drops column\n",
    "                          index = arriveDelayOutlierindices, # this takes a list as input\n",
    "                          inplace = True)         # not overwritten by default \n",
    "# Check the clean data\n",
    "arriveDelayDataClean['Arrival Delay in Minutes'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476b0fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(3, 1, figsize=(64, 32))\n",
    "sb.boxplot(data = arriveDelayDataClean[['Arrival Delay in Minutes']], orient = \"h\", ax = axes[0])\n",
    "sb.histplot(data = arriveDelayDataClean[['Arrival Delay in Minutes']], ax = axes[1])\n",
    "sb.violinplot(data = arriveDelayDataClean[['Arrival Delay in Minutes']], orient = \"h\", ax = axes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb901904",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(3, 1, figsize=(64, 48))\n",
    "sb.boxplot(data = arriveDelayDataClean, orient = \"h\", ax = axes[0],\n",
    "          x ='Arrival Delay in Minutes', y = 'satisfaction_v2')\n",
    "sb.kdeplot(data = arriveDelayDataClean, ax = axes[1],\n",
    "          x ='Arrival Delay in Minutes', hue = 'satisfaction_v2')\n",
    "sb.violinplot(data = arriveDelayDataClean, orient = \"h\", ax = axes[2],\n",
    "          x ='Arrival Delay in Minutes', y = 'satisfaction_v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4243d04d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a43f67",
   "metadata": {},
   "source": [
    "<a id=\"models\"></a>\n",
    "## Models\n",
    "### Creating a Model for satisfaction_v2 : Attempt 1 - Multi-Variate Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de009d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the encoder from sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "# OneHotEncoding of categorical predictors (not the response)\n",
    "satisfactionData_cat = satisfactionData[['Class']]\n",
    "ohe.fit(satisfactionData_cat)\n",
    "satisfactionData_cat_ohe = pd.DataFrame(ohe.transform(satisfactionData_cat).toarray(), \n",
    "                                  columns=ohe.get_feature_names(satisfactionData_cat.columns))\n",
    "\n",
    "# Check the encoded variables\n",
    "satisfactionData_cat_ohe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45721def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining Ordinal Category variables with the OHE Categorical variables\n",
    "'''\n",
    "list of columns \n",
    "['Seat comfort','Food and drink','Inflight wifi service','Inflight entertainment',\n",
    "'On-board service','Leg room service', 'Checkin service','Cleanliness']\n",
    "\n",
    "'''\n",
    "satisfactionData_num = satisfactionData[['Seat comfort','Food and drink',\n",
    "'Inflight wifi service','Inflight entertainment','On-board service','Leg room service',\n",
    "'Checkin service','Cleanliness']]\n",
    "satisfactionData_res = satisfactionData['satisfaction_v2']\n",
    "satisfactionData_ohe = pd.concat([satisfactionData_num, satisfactionData_cat_ohe, satisfactionData_res], \n",
    "                           sort = False, axis = 1).reindex(index=satisfactionData_num.index)\n",
    "\n",
    "# Check the final dataframe\n",
    "satisfactionData_ohe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9148bc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = satisfactionData;\n",
    "#print(test)\n",
    "scale_mapper = {0:0, 1:1, 2:2, 3:3, 4:4, 5:5}\n",
    "scaled = test[\"Seat comfort\"].replace(scale_mapper) \n",
    "\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "cat_type_ratings = CategoricalDtype(categories=[0,1,2,3,4,5], ordered=True)\n",
    "test[\"Seat comfort\"].astype(cat_type_ratings, )\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0edf68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential models and functions from sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(satisfactionData_ohe['satisfaction_v2'])\n",
    "X = pd.DataFrame(satisfactionData_ohe.drop('satisfaction_v2', axis = 1))\n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# Decision Tree using Train Data\n",
    "dectree = DecisionTreeClassifier(max_depth = 3)  # change max_depth to experiment\n",
    "dectree.fit(X_train, y_train)                    # train the decision tree model\n",
    "\n",
    "# Plot the trained Decision Tree\n",
    "f = plt.figure(figsize=(24,24))\n",
    "plot_tree(dectree, filled=True, rounded=True, \n",
    "          feature_names=X_train.columns, \n",
    "          class_names=[\"neutral or dissatisfied\",\"satisfied\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2544c20b",
   "metadata": {},
   "source": [
    "### Check the accuracy of the Model\n",
    "\n",
    "Print the Classification Accuracy and all other Accuracy Measures from the Confusion Matrix.  \n",
    "\n",
    "| Confusion Matrix  |       |        |        |      \n",
    "| :---              | :---: | :----: | :----: |         \n",
    "| Actual Negative   |  (0)  |   TN   |   FP   |             \n",
    "| Actual Positive   |  (1)  |   FN   |   TP   |       \n",
    "|                   |       |   (0)   |   (1)   |       \n",
    "|                   |       | Predicted Negative    |   Predicted Postitive  |     \n",
    "\n",
    "\n",
    "* `TPR = TP / (TP + FN)` : True Positive Rate = True Positives / All Positives    \n",
    "* `TNR = TN / (TN + FP)` : True Negative Rate = True Negatives / All Negatives    \n",
    "\n",
    "* `FPR = FP / (TN + FP)` : False Positive Rate = False Positives / All Negatives \n",
    "* `FNR = FN / (TP + FN)` : False Negative Rate = False Negatives / All Positives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ea9ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the Response corresponding to Predictors\n",
    "y_train_pred = dectree.predict(X_train)\n",
    "\n",
    "# Print the Classification Accuracy\n",
    "print(\"Train Data\")\n",
    "print(\"Accuracy  :\\t\", dectree.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Print the Accuracy Measures from the Confusion Matrix\n",
    "cmTrain = confusion_matrix(y_train, y_train_pred)\n",
    "tpTrain = cmTrain[1][1] # True Positives : Good (1) predicted Good (1)\n",
    "fpTrain = cmTrain[0][1] # False Positives : Bad (0) predicted Good (1)\n",
    "tnTrain = cmTrain[0][0] # True Negatives : Bad (0) predicted Bad (0)\n",
    "fnTrain = cmTrain[1][0] # False Negatives : Good (1) predicted Bad (0)\n",
    "\n",
    "print(\"TPR Train :\\t\", (tpTrain/(tpTrain + fnTrain)))\n",
    "print(\"TNR Train :\\t\", (tnTrain/(tnTrain + fpTrain)))\n",
    "print()\n",
    "\n",
    "print(\"FPR Train :\\t\", (fpTrain/(tnTrain + fpTrain)))\n",
    "print(\"FNR Train :\\t\", (fnTrain/(tpTrain + fnTrain)))\n",
    "\n",
    "# Plot the two-way Confusion Matrix\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce51ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required metric from sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predict the Response corresponding to Predictors\n",
    "y_test_pred = dectree.predict(X_test)\n",
    "\n",
    "# Print the Classification Accuracy\n",
    "print(\"Test Data\")\n",
    "print(\"Accuracy  :\\t\", dectree.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Print the Accuracy Measures from the Confusion Matrix\n",
    "cmTest = confusion_matrix(y_test, y_test_pred)\n",
    "tpTest = cmTest[1][1] # True Positives : Good (1) predicted Good (1)\n",
    "fpTest = cmTest[0][1] # False Positives : Bad (0) predicted Good (1)\n",
    "tnTest = cmTest[0][0] # True Negatives : Bad (0) predicted Bad (0)\n",
    "fnTest = cmTest[1][0] # False Negatives : Good (1) predicted Bad (0)\n",
    "\n",
    "print(\"TPR Test :\\t\", (tpTest/(tpTest + fnTest)))\n",
    "print(\"TNR Test :\\t\", (tnTest/(tnTest + fpTest)))\n",
    "print()\n",
    "\n",
    "print(\"FPR Test :\\t\", (fpTest/(fpTest + tnTest)))\n",
    "print(\"FNR Test :\\t\", (fnTest/(fnTest + tpTest)))\n",
    "\n",
    "# Plot the two-way Confusion Matrix\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e77827",
   "metadata": {},
   "source": [
    "### Create a Model for satisfaction_v2 : Attempt 2 - Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d170359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample Bad to match Good\n",
    "from sklearn.utils import resample\n",
    "satisfactionBad = satisfactionData_ohe[satisfactionData_ohe.satisfaction_v2 == 'neutral or dissatisfied']\n",
    "satisfactionGood = satisfactionData_ohe[satisfactionData_ohe.satisfaction_v2 == 'satisfied']\n",
    " \n",
    "# Upsample the Bad samples\n",
    "satisfactionBad_up = resample(satisfactionBad, \n",
    "                        replace=True,                     # sample with replacement\n",
    "                        n_samples=satisfactionGood.shape[0])    # to match number of Good\n",
    " \n",
    "# Combine the two classes back after upsampling\n",
    "satisfactionData_ohe_up = pd.concat([satisfactionGood, satisfactionBad_up])\n",
    " \n",
    "# Check the ratio of the classes\n",
    "satisfactionData_ohe_up['satisfaction_v2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b19f58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick plot to check the balanced classes visually\n",
    "sb.catplot(y = 'satisfaction_v2', data = satisfactionData_ohe_up, kind = \"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cba555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that the OHE is still in place\n",
    "# and that the samples have now increased\n",
    "satisfactionData_ohe_up.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fec7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential models and functions from sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(satisfactionData_ohe_up['satisfaction_v2'])\n",
    "X = pd.DataFrame(satisfactionData_ohe_up.drop('satisfaction_v2', axis = 1))\n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# Decision Tree using Train Data\n",
    "dectree = DecisionTreeClassifier(max_depth = 4)  # change max_depth to experiment\n",
    "dectree.fit(X_train, y_train)                    # train the decision tree model\n",
    "\n",
    "# Plot the trained Decision Tree\n",
    "f = plt.figure(figsize=(24,24))\n",
    "plot_tree(dectree, filled=True, rounded=True, \n",
    "          feature_names=X_train.columns, \n",
    "          class_names=[\"neutral or dissatisfied\",\"satisfied\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71d38c2",
   "metadata": {},
   "source": [
    "#### Check the accuracy of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a51c1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the Response corresponding to Predictors\n",
    "y_train_pred = dectree.predict(X_train)\n",
    "\n",
    "# Print the Classification Accuracy\n",
    "print(\"Train Data\")\n",
    "print(\"Accuracy  :\\t\", dectree.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Print the Accuracy Measures from the Confusion Matrix\n",
    "cmTrain = confusion_matrix(y_train, y_train_pred)\n",
    "tpTrain = cmTrain[1][1] # True Positives : Good (1) predicted Good (1)\n",
    "fpTrain = cmTrain[0][1] # False Positives : Bad (0) predicted Good (1)\n",
    "tnTrain = cmTrain[0][0] # True Negatives : Bad (0) predicted Bad (0)\n",
    "fnTrain = cmTrain[1][0] # False Negatives : Good (1) predicted Bad (0)\n",
    "\n",
    "print(\"TPR Train :\\t\", (tpTrain/(tpTrain + fnTrain)))\n",
    "print(\"TNR Train :\\t\", (tnTrain/(tnTrain + fpTrain)))\n",
    "print()\n",
    "\n",
    "print(\"FPR Train :\\t\", (fpTrain/(tnTrain + fpTrain)))\n",
    "print(\"FNR Train :\\t\", (fnTrain/(tpTrain + fnTrain)))\n",
    "\n",
    "# Plot the two-way Confusion Matrix\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b507a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required metric from sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predict the Response corresponding to Predictors\n",
    "y_test_pred = dectree.predict(X_test)\n",
    "\n",
    "# Print the Classification Accuracy\n",
    "print(\"Test Data\")\n",
    "print(\"Accuracy  :\\t\", dectree.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Print the Accuracy Measures from the Confusion Matrix\n",
    "cmTest = confusion_matrix(y_test, y_test_pred)\n",
    "tpTest = cmTest[1][1] # True Positives : Good (1) predicted Good (1)\n",
    "fpTest = cmTest[0][1] # False Positives : Bad (0) predicted Good (1)\n",
    "tnTest = cmTest[0][0] # True Negatives : Bad (0) predicted Bad (0)\n",
    "fnTest = cmTest[1][0] # False Negatives : Good (1) predicted Bad (0)\n",
    "\n",
    "print(\"TPR Test :\\t\", (tpTest/(tpTest + fnTest)))\n",
    "print(\"TNR Test :\\t\", (tnTest/(tnTest + fpTest)))\n",
    "print()\n",
    "\n",
    "print(\"FPR Test :\\t\", (fpTest/(fpTest + tnTest)))\n",
    "print(\"FNR Test :\\t\", (fnTest/(fnTest + tpTest)))\n",
    "\n",
    "# Plot the two-way Confusion Matrix\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b584ee",
   "metadata": {},
   "source": [
    "### Create a Model for satisfaction_v2 : Attempt 3 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e759fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential models and functions from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(satisfactionData_ohe_up['satisfaction_v2'])\n",
    "X = pd.DataFrame(satisfactionData_ohe_up.drop('satisfaction_v2', axis = 1))\n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6526a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomForestClassifier model from Scikit-Learn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create the Random Forest object\n",
    "rforest = RandomForestClassifier(n_estimators = 100,  # n_estimators denote number of trees\n",
    "                                 max_depth = 4)       # set the maximum depth of each tree\n",
    "\n",
    "# Fit Random Forest on Train Data\n",
    "rforest.fit(X_train, y_train.satisfaction_v2.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653eb04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import confusion_matrix from Scikit-Learn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predict the Response corresponding to Predictors\n",
    "y_train_pred = rforest.predict(X_train)\n",
    "\n",
    "# Print the Classification Accuracy\n",
    "print(\"Train Data\")\n",
    "print(\"Accuracy  :\\t\", rforest.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Print the Accuracy Measures from the Confusion Matrix\n",
    "cmTrain = confusion_matrix(y_train, y_train_pred)\n",
    "tpTrain = cmTrain[1][1] # True Positives : Good (1) predicted Good (1)\n",
    "fpTrain = cmTrain[0][1] # False Positives : Bad (0) predicted Good (1)\n",
    "tnTrain = cmTrain[0][0] # True Negatives : Bad (0) predicted Bad (0)\n",
    "fnTrain = cmTrain[1][0] # False Negatives : Good (1) predicted Bad (0)\n",
    "\n",
    "print(\"TPR Train :\\t\", (tpTrain/(tpTrain + fnTrain)))\n",
    "print(\"TNR Train :\\t\", (tnTrain/(tnTrain + fpTrain)))\n",
    "print()\n",
    "\n",
    "print(\"FPR Train :\\t\", (fpTrain/(tnTrain + fpTrain)))\n",
    "print(\"FNR Train :\\t\", (fnTrain/(tpTrain + fnTrain)))\n",
    "\n",
    "# Plot the two-way Confusion Matrix\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b83ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required metric from sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predict the Response corresponding to Predictors\n",
    "y_test_pred = rforest.predict(X_test)\n",
    "\n",
    "# Print the Classification Accuracy\n",
    "print(\"Test Data\")\n",
    "print(\"Accuracy  :\\t\", rforest.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Print the Accuracy Measures from the Confusion Matrix\n",
    "cmTest = confusion_matrix(y_test, y_test_pred)\n",
    "tpTest = cmTest[1][1] # True Positives : Good (1) predicted Good (1)\n",
    "fpTest = cmTest[0][1] # False Positives : Bad (0) predicted Good (1)\n",
    "tnTest = cmTest[0][0] # True Negatives : Bad (0) predicted Bad (0)\n",
    "fnTest = cmTest[1][0] # False Negatives : Good (1) predicted Bad (0)\n",
    "\n",
    "print(\"TPR Test :\\t\", (tpTest/(tpTest + fnTest)))\n",
    "print(\"TNR Test :\\t\", (tnTest/(tnTest + fpTest)))\n",
    "print()\n",
    "\n",
    "print(\"FPR Test :\\t\", (fpTest/(fpTest + tnTest)))\n",
    "print(\"FNR Test :\\t\", (fnTest/(fnTest + tpTest)))\n",
    "\n",
    "# Plot the two-way Confusion Matrix\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4abd152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential models and functions from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(satisfactionData_ohe_up['satisfaction_v2'])\n",
    "X = pd.DataFrame(satisfactionData_ohe_up.drop('satisfaction_v2', axis = 1))\n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "# Import RandomForestClassifier model from Scikit-Learn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create the Random Forest object\n",
    "rforest = RandomForestClassifier(n_estimators = 1000,  # CHANGE AND EXPERIMENT\n",
    "                                 max_depth = 4)       # CHANGE AND EXPERIMENT\n",
    "\n",
    "# Fit Random Forest on Train Data\n",
    "rforest.fit(X_train, y_train.satisfaction_v2.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e218b296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import confusion_matrix from Scikit-Learn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predict the Response corresponding to Predictors\n",
    "y_train_pred = rforest.predict(X_train)\n",
    "\n",
    "# Print the Classification Accuracy\n",
    "print(\"Train Data\")\n",
    "print(\"Accuracy  :\\t\", rforest.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Print the Accuracy Measures from the Confusion Matrix\n",
    "cmTrain = confusion_matrix(y_train, y_train_pred)\n",
    "tpTrain = cmTrain[1][1] # True Positives : Good (1) predicted Good (1)\n",
    "fpTrain = cmTrain[0][1] # False Positives : Bad (0) predicted Good (1)\n",
    "tnTrain = cmTrain[0][0] # True Negatives : Bad (0) predicted Bad (0)\n",
    "fnTrain = cmTrain[1][0] # False Negatives : Good (1) predicted Bad (0)\n",
    "\n",
    "print(\"TPR Train :\\t\", (tpTrain/(tpTrain + fnTrain)))\n",
    "print(\"TNR Train :\\t\", (tnTrain/(tnTrain + fpTrain)))\n",
    "print()\n",
    "\n",
    "print(\"FPR Train :\\t\", (fpTrain/(tnTrain + fpTrain)))\n",
    "print(\"FNR Train :\\t\", (fnTrain/(tpTrain + fnTrain)))\n",
    "\n",
    "# Plot the two-way Confusion Matrix\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c03b7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required metric from sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predict the Response corresponding to Predictors\n",
    "y_test_pred = rforest.predict(X_test)\n",
    "\n",
    "# Print the Classification Accuracy\n",
    "print(\"Test Data\")\n",
    "print(\"Accuracy  :\\t\", rforest.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Print the Accuracy Measures from the Confusion Matrix\n",
    "cmTest = confusion_matrix(y_test, y_test_pred)\n",
    "tpTest = cmTest[1][1] # True Positives : Good (1) predicted Good (1)\n",
    "fpTest = cmTest[0][1] # False Positives : Bad (0) predicted Good (1)\n",
    "tnTest = cmTest[0][0] # True Negatives : Bad (0) predicted Bad (0)\n",
    "fnTest = cmTest[1][0] # False Negatives : Good (1) predicted Bad (0)\n",
    "\n",
    "print(\"TPR Test :\\t\", (tpTest/(tpTest + fnTest)))\n",
    "print(\"TNR Test :\\t\", (tnTest/(tnTest + fpTest)))\n",
    "print()\n",
    "\n",
    "print(\"FPR Test :\\t\", (fpTest/(fpTest + tnTest)))\n",
    "print(\"FNR Test :\\t\", (fnTest/(fnTest + tpTest)))\n",
    "\n",
    "# Plot the two-way Confusion Matrix\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053662de",
   "metadata": {},
   "source": [
    "#### Increase the Depth of Decision Trees in the Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eded9bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential models and functions from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(satisfactionData_ohe_up['satisfaction_v2'])\n",
    "X = pd.DataFrame(satisfactionData_ohe_up.drop('satisfaction_v2', axis = 1))\n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "# Import RandomForestClassifier model from Scikit-Learn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create the Random Forest object\n",
    "rforest = RandomForestClassifier(n_estimators = 100,  # CHANGE AND EXPERIMENT\n",
    "                                 max_depth = 10)       # CHANGE AND EXPERIMENT\n",
    "\n",
    "# Fit Random Forest on Train Data\n",
    "rforest.fit(X_train, y_train.satisfaction_v2.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d38545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import confusion_matrix from Scikit-Learn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predict the Response corresponding to Predictors\n",
    "y_train_pred = rforest.predict(X_train)\n",
    "\n",
    "# Print the Classification Accuracy\n",
    "print(\"Train Data\")\n",
    "print(\"Accuracy  :\\t\", rforest.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Print the Accuracy Measures from the Confusion Matrix\n",
    "cmTrain = confusion_matrix(y_train, y_train_pred)\n",
    "tpTrain = cmTrain[1][1] # True Positives : Good (1) predicted Good (1)\n",
    "fpTrain = cmTrain[0][1] # False Positives : Bad (0) predicted Good (1)\n",
    "tnTrain = cmTrain[0][0] # True Negatives : Bad (0) predicted Bad (0)\n",
    "fnTrain = cmTrain[1][0] # False Negatives : Good (1) predicted Bad (0)\n",
    "\n",
    "print(\"TPR Train :\\t\", (tpTrain/(tpTrain + fnTrain)))\n",
    "print(\"TNR Train :\\t\", (tnTrain/(tnTrain + fpTrain)))\n",
    "print()\n",
    "\n",
    "print(\"FPR Train :\\t\", (fpTrain/(tnTrain + fpTrain)))\n",
    "print(\"FNR Train :\\t\", (fnTrain/(tpTrain + fnTrain)))\n",
    "\n",
    "# Plot the two-way Confusion Matrix\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75af809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required metric from sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predict the Response corresponding to Predictors\n",
    "y_test_pred = rforest.predict(X_test)\n",
    "\n",
    "# Print the Classification Accuracy\n",
    "print(\"Test Data\")\n",
    "print(\"Accuracy  :\\t\", rforest.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Print the Accuracy Measures from the Confusion Matrix\n",
    "cmTest = confusion_matrix(y_test, y_test_pred)\n",
    "tpTest = cmTest[1][1] # True Positives : Good (1) predicted Good (1)\n",
    "fpTest = cmTest[0][1] # False Positives : Bad (0) predicted Good (1)\n",
    "tnTest = cmTest[0][0] # True Negatives : Bad (0) predicted Bad (0)\n",
    "fnTest = cmTest[1][0] # False Negatives : Good (1) predicted Bad (0)\n",
    "\n",
    "print(\"TPR Test :\\t\", (tpTest/(tpTest + fnTest)))\n",
    "print(\"TNR Test :\\t\", (tnTest/(tnTest + fpTest)))\n",
    "print()\n",
    "\n",
    "print(\"FPR Test :\\t\", (fpTest/(fpTest + tnTest)))\n",
    "print(\"FNR Test :\\t\", (fnTest/(fnTest + tpTest)))\n",
    "\n",
    "# Plot the two-way Confusion Matrix\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e739dc3",
   "metadata": {},
   "source": [
    "#### Increase both Number and Depth of Decision Trees in the Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d86d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential models and functions from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(satisfactionData_ohe_up['satisfaction_v2'])\n",
    "X = pd.DataFrame(satisfactionData_ohe_up.drop('satisfaction_v2', axis = 1))\n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "# Import RandomForestClassifier model from Scikit-Learn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create the Random Forest object\n",
    "rforest = RandomForestClassifier(n_estimators = 1000,  # CHANGE AND EXPERIMENT\n",
    "                                 max_depth = 10)       # CHANGE AND EXPERIMENT\n",
    "\n",
    "# Fit Random Forest on Train Data\n",
    "rforest.fit(X_train, y_train.satisfaction_v2.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6278120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import confusion_matrix from Scikit-Learn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predict the Response corresponding to Predictors\n",
    "y_train_pred = rforest.predict(X_train)\n",
    "\n",
    "# Print the Classification Accuracy\n",
    "print(\"Train Data\")\n",
    "print(\"Accuracy  :\\t\", rforest.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Print the Accuracy Measures from the Confusion Matrix\n",
    "cmTrain = confusion_matrix(y_train, y_train_pred)\n",
    "tpTrain = cmTrain[1][1] # True Positives : Good (1) predicted Good (1)\n",
    "fpTrain = cmTrain[0][1] # False Positives : Bad (0) predicted Good (1)\n",
    "tnTrain = cmTrain[0][0] # True Negatives : Bad (0) predicted Bad (0)\n",
    "fnTrain = cmTrain[1][0] # False Negatives : Good (1) predicted Bad (0)\n",
    "\n",
    "print(\"TPR Train :\\t\", (tpTrain/(tpTrain + fnTrain)))\n",
    "print(\"TNR Train :\\t\", (tnTrain/(tnTrain + fpTrain)))\n",
    "print()\n",
    "\n",
    "print(\"FPR Train :\\t\", (fpTrain/(tnTrain + fpTrain)))\n",
    "print(\"FNR Train :\\t\", (fnTrain/(tpTrain + fnTrain)))\n",
    "\n",
    "# Plot the two-way Confusion Matrix\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fde9c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required metric from sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predict the Response corresponding to Predictors\n",
    "y_test_pred = rforest.predict(X_test)\n",
    "\n",
    "# Print the Classification Accuracy\n",
    "print(\"Test Data\")\n",
    "print(\"Accuracy  :\\t\", rforest.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Print the Accuracy Measures from the Confusion Matrix\n",
    "cmTest = confusion_matrix(y_test, y_test_pred)\n",
    "tpTest = cmTest[1][1] # True Positives : Good (1) predicted Good (1)\n",
    "fpTest = cmTest[0][1] # False Positives : Bad (0) predicted Good (1)\n",
    "tnTest = cmTest[0][0] # True Negatives : Bad (0) predicted Bad (0)\n",
    "fnTest = cmTest[1][0] # False Negatives : Good (1) predicted Bad (0)\n",
    "\n",
    "print(\"TPR Test :\\t\", (tpTest/(tpTest + fnTest)))\n",
    "print(\"TNR Test :\\t\", (tnTest/(tnTest + fpTest)))\n",
    "print()\n",
    "\n",
    "print(\"FPR Test :\\t\", (fpTest/(fpTest + tnTest)))\n",
    "print(\"FNR Test :\\t\", (fnTest/(fnTest + tpTest)))\n",
    "\n",
    "# Plot the two-way Confusion Matrix\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b25af72",
   "metadata": {},
   "source": [
    "### Creating a Model for satisfaction_v2 : Attempt 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a123a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomForestClassifier model from Scikit-Learn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(satisfactionData_ohe_up['satisfaction_v2'])\n",
    "X = pd.DataFrame(satisfactionData_ohe_up.drop('satisfaction_v2', axis = 1))\n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a47261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearch for hyperparameter tuning using Cross-Validation (CV)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the Hyper-parameter Grid to search on, in case of Random Forest\n",
    "param_grid = {'n_estimators': np.arange(100,1001,100),   # number of trees 100, 200, ..., 1000\n",
    "              'max_depth': np.arange(2, 11)}             # depth of trees 2, 3, 4, 5, ..., 10\n",
    "\n",
    "#param_grid = {'n_estimators': np.arange(10,101,10),\n",
    "#              'max_depth': np.arange(2, 4)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41061be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Hyper-parameter Grid\n",
    "hpGrid = GridSearchCV(RandomForestClassifier(),   # the model family\n",
    "                      param_grid,                 # the search grid\n",
    "                      cv = 3,                     # 5-fold cross-validation\n",
    "                      scoring = 'accuracy')       # score to evaluate\n",
    "\n",
    "# Train the models using Cross-Validation\n",
    "hpGrid.fit(X_train, y_train.satisfaction_v2.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e6510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the best Model or the best set of Hyper-parameters\n",
    "print(hpGrid.best_estimator_)\n",
    "\n",
    "# Print the score (accuracy) of the best Model after CV\n",
    "print(np.abs(hpGrid.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2223da52",
   "metadata": {},
   "source": [
    "#### Use the Best Model found through GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8a77d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential models and functions from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(satisfactionData_ohe_up['satisfaction_v2'])\n",
    "X = pd.DataFrame(satisfactionData_ohe_up.drop('satisfaction_v2', axis = 1))\n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "# Import RandomForestClassifier model from Scikit-Learn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create the Random Forest object\n",
    "rforest = RandomForestClassifier(n_estimators = 400,   # found using GridSearchCV\n",
    "                                 max_depth = 10)       # found using GridSearchCV\n",
    "\n",
    "# Fit Random Forest on Train Data\n",
    "rforest.fit(X_train, y_train.satisfaction_v2.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d78ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import confusion_matrix from Scikit-Learn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predict the Response corresponding to Predictors\n",
    "y_train_pred = rforest.predict(X_train)\n",
    "\n",
    "# Print the Classification Accuracy\n",
    "print(\"Train Data\")\n",
    "print(\"Accuracy  :\\t\", rforest.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Print the Accuracy Measures from the Confusion Matrix\n",
    "cmTrain = confusion_matrix(y_train, y_train_pred)\n",
    "tpTrain = cmTrain[1][1] # True Positives : Good (1) predicted Good (1)\n",
    "fpTrain = cmTrain[0][1] # False Positives : Bad (0) predicted Good (1)\n",
    "tnTrain = cmTrain[0][0] # True Negatives : Bad (0) predicted Bad (0)\n",
    "fnTrain = cmTrain[1][0] # False Negatives : Good (1) predicted Bad (0)\n",
    "\n",
    "print(\"TPR Train :\\t\", (tpTrain/(tpTrain + fnTrain)))\n",
    "print(\"TNR Train :\\t\", (tnTrain/(tnTrain + fpTrain)))\n",
    "print()\n",
    "\n",
    "print(\"FPR Train :\\t\", (fpTrain/(tnTrain + fpTrain)))\n",
    "print(\"FNR Train :\\t\", (fnTrain/(tpTrain + fnTrain)))\n",
    "\n",
    "# Plot the two-way Confusion Matrix\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ed3a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required metric from sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predict the Response corresponding to Predictors\n",
    "y_test_pred = rforest.predict(X_test)\n",
    "\n",
    "# Print the Classification Accuracy\n",
    "print(\"Test Data\")\n",
    "print(\"Accuracy  :\\t\", rforest.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Print the Accuracy Measures from the Confusion Matrix\n",
    "cmTest = confusion_matrix(y_test, y_test_pred)\n",
    "tpTest = cmTest[1][1] # True Positives : Good (1) predicted Good (1)\n",
    "fpTest = cmTest[0][1] # False Positives : Bad (0) predicted Good (1)\n",
    "tnTest = cmTest[0][0] # True Negatives : Bad (0) predicted Bad (0)\n",
    "fnTest = cmTest[1][0] # False Negatives : Good (1) predicted Bad (0)\n",
    "\n",
    "print(\"TPR Test :\\t\", (tpTest/(tpTest + fnTest)))\n",
    "print(\"TNR Test :\\t\", (tnTest/(tnTest + fpTest)))\n",
    "print()\n",
    "\n",
    "print(\"FPR Test :\\t\", (fpTest/(fpTest + tnTest)))\n",
    "print(\"FNR Test :\\t\", (fnTest/(fnTest + tpTest)))\n",
    "\n",
    "# Plot the two-way Confusion Matrix\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe502e7",
   "metadata": {},
   "source": [
    "### Create a Model for satisfaction_v2 : Attempt 5 - Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8668ba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['id','satisfaction_v2','Gender','Customer Type',\n",
    "'Age','Type of Travel','Class','Flight Distance',\n",
    "'Seat comfort','Departure/Arrival time convenient','Food and drink','Gate location','Inflight wifi service',\n",
    "'Inflight entertainment','Online support','Ease of Online booking','On-board service','Leg room service','Baggage handling',\n",
    "'Checkin service','Cleanliness','Online boarding','Departure Delay in Minutes','Arrival Delay in Minutes']\n",
    "# load dataset, remove header\n",
    "pima = pd.read_csv(\"satisfaction.csv\", header=1, names=col_names)\n",
    "#pima.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036f8dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of columns ['Seat comfort',Food and drink',\n",
    "#'Inflight wifi service','Inflight entertainment','On-board service','Leg room service',\n",
    "#'Checkin service','Cleanliness']\n",
    "feature_cols = ['Seat comfort','Food and drink',\n",
    "'Inflight wifi service','Inflight entertainment','On-board service','Leg room service',\n",
    "'Checkin service','Cleanliness']\n",
    "\n",
    "X = pima[feature_cols] # Features\n",
    "y = pima.satisfaction_v2 # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e005444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dfde62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=500) # increase the limit else will get warning\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f86aacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the metrics class\n",
    "from sklearn import metrics\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72992dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f853966",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [0,1] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861d796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos_label='satisfied' will take satisfied as positive else will take 1 as default\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred,pos_label='satisfied'))\n",
    "print(\"Recall:\", metrics.recall_score(y_test, y_pred,pos_label='satisfied'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2d3214",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logreg.predict_proba(X_test)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba,pos_label='satisfied')\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f336974",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Receiver Operating Characteristic(ROC) Curve\n",
    "\n",
    "A plot for the true positive rate against the false positive rate.\n",
    "\n",
    "AUC score of ~0.87. Consider good. As 1 represents perfect classifier and 0.5 represents a worthless classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
